{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker_pyspark\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window as W\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql.functions import asc, desc, col, when, from_unixtime, lit ,year, month, dayofmonth, hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "# Configure Spark to use the SageMaker Spark dependency jars\n",
    "jars = sagemaker_pyspark.classpath_jars()\n",
    "\n",
    "classpath = \":\".join(sagemaker_pyspark.classpath_jars())\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "   .config(\"spark.driver.extraClassPath\", classpath)\\\n",
    "   .master(\"local[*]\")\\\n",
    "   .getOrCreate()\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipin= '::21e:5e09:23c:235e'\n",
    "\n",
    "params = sqlContext.read\\\n",
    "   .parquet(\"s3a://cb-prod-analytics/data-parquet/params-cl03/year=2018/month=11\")\\\n",
    "       .withColumn('hubTimestamp', col('parameter.ts'))\\\n",
    "       .withColumn('name', col('parameter.name'))\\\n",
    "       .withColumn('value', col('parameter.value'))\\\n",
    "       .filter((col('clipinId')==clipin) & (col('name').isin('Appliance_Flow_Temperature')))\\\n",
    "       .select(col('clipinId'),col('hubTimestamp'), col('name'), col('value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df, sparkdf=True):\n",
    "    '''\n",
    "    @Description: prepare data for plotting\n",
    "    @Params param1: df, Dataframe\n",
    "    @Params param2: sparkdf, bool indicating if the param1 is a pandas or Spark Dataframe\n",
    "    @Return: pandas dataframe with additional date and processed columns\n",
    "    @Dependencies: pandas\n",
    "    '''\n",
    "    ret_param_list = ['Appliance_Flow_Temperature',\n",
    "                     'Appliance_Return_Temperature',\n",
    "                     'Appliance_Domestic_Hot_Water_Temperature',\n",
    "                     'Appliance_Current',\n",
    "                     'Appliance_Phase_Power_Factor',\n",
    "                     'Domestic_Hot_Water_Demand',\n",
    "                     'Central_Heating_Demand']\n",
    "\n",
    "    bosch_param_lst = ['ChPump',\n",
    "                      'GasValMain',\n",
    "                      'Fan',\n",
    "                      'RthSwitch',\n",
    "                      'PrimT',\n",
    "                      'RetT',\n",
    "                      'ActPow',\n",
    "                      'HwTOutlet',\n",
    "                      'HwFlow']\n",
    "\n",
    "\n",
    "    if sparkdf:\n",
    "        df = df.toPandas()\n",
    "    \n",
    "    \n",
    "    mask = df['name'].isin(ret_param_list+bosch_param_lst)\n",
    "    df = df [mask]\n",
    "    \n",
    "    df['hubTimestamp'] = pd.to_numeric(df['hubTimestamp'])\n",
    "    \n",
    "    df.sort_values(by=['clipinId','hubTimestamp'],ascending=[True, True], inplace=True)\n",
    "    \n",
    "    df['ts'] = pd.to_datetime(df['hubTimestamp'],unit='ms')\n",
    "    \n",
    "    \n",
    "    df['value']= df['value'].str.lower().str.replace(r'^(?!off$|on$|\\d|true$|false$|yes$|no$).*','-999')\n",
    "    \n",
    "\n",
    "    \n",
    "    df['value']= df['value'].str.lower().str.replace(r'(off$|no$|false$)','0')\n",
    "    df['value']= df['value'].str.lower().str.replace(r'(on$|yes$|true$)','1')\n",
    "    \n",
    "    df['value'] = df['value'].replace({'0': False,\n",
    "                                      '1': True,\n",
    "                                     })\n",
    "    \n",
    "    \n",
    "    df = df.drop(df[df.value =='-999'].index).reset_index(drop=True)\n",
    "    \n",
    "    df['value'] = pd.to_numeric(df['value'])\n",
    "    dup_cols = ['clipinId','ts','name']\n",
    "    df.drop_duplicates(subset=dup_cols, keep='first' ,inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import boto3\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "df.to_csv(csv_buffer, index=False)\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "s3_resource.Object('hackathon-nerual-network-datasets', clipin[2:] + '_Appliance_Flow_Temperature.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
